#!/usr/bin/env python3
import argparse
import csv
from pathlib import Path


def main() -> int:
    parser = argparse.ArgumentParser(description="Build BIG5 zh-CN xu bootstrap norms CSV and merge into seed file.")
    parser.add_argument(
        "--input",
        default="backend/content_packs/BIG5_OCEAN/v1/raw/norm_stats.csv",
        help="Input raw norm_stats.csv path",
    )
    parser.add_argument(
        "--seed",
        default="backend/resources/norms/big5/big5_norm_stats_seed.csv",
        help="Seed CSV path generated by en bootstrap script",
    )
    args = parser.parse_args()

    root = Path(__file__).resolve().parents[2]
    in_path = (root.parent / args.input).resolve() if args.input.startswith("backend/") else (root / args.input).resolve()
    seed_path = (root.parent / args.seed).resolve() if args.seed.startswith("backend/") else (root / args.seed).resolve()

    zh_domains = []
    global_facets = []
    with in_path.open("r", encoding="utf-8", newline="") as f:
        reader = csv.DictReader(f)
        for row in reader:
            gid = (row.get("group_id") or "").strip()
            level = (row.get("metric_level") or "").strip().lower()
            code = (row.get("metric_code") or "").strip().upper()

            if gid == "zh-CN_all" and level == "domain":
                zh_domains.append((level, code, row))
            if gid == "global_all" and level == "facet":
                global_facets.append((level, code, row))

    if len(zh_domains) != 5:
        raise SystemExit(f"expected 5 zh-CN domain rows, got {len(zh_domains)}")
    if len(global_facets) != 30:
        raise SystemExit(f"expected 30 global facet rows, got {len(global_facets)}")

    fieldnames = [
        "scale_code", "norms_version", "locale", "region", "group_id", "gender", "age_min", "age_max",
        "metric_level", "metric_code", "mean", "sd", "sample_n", "source_id", "source_type", "status",
        "is_active", "published_at",
    ]

    zh_rows = []
    for level, code, row in zh_domains + global_facets:
        zh_rows.append({
            "scale_code": "BIG5_OCEAN",
            "norms_version": "2026Q1_xu_v1",
            "locale": "zh-CN",
            "region": "CN_MAINLAND",
            "group_id": "zh-CN_xu_all_18-60",
            "gender": "ALL",
            "age_min": "18",
            "age_max": "60",
            "metric_level": level,
            "metric_code": code,
            "mean": f"{float(row.get('mean') or 0):.3f}",
            "sd": f"{float(row.get('sd') or 0):.3f}",
            "sample_n": str(int(float(row.get("sample_n") or 0))),
            "source_id": "ZH_CN_IPIPNEO120_XU",
            "source_type": "peer_reviewed",
            "status": "BOOTSTRAP",
            "is_active": "1",
            "published_at": "2026-02-21T00:00:00Z",
        })

    merged = []
    if seed_path.exists():
        with seed_path.open("r", encoding="utf-8", newline="") as f:
            reader = csv.DictReader(f)
            for row in reader:
                if (row.get("group_id") or "") == "zh-CN_xu_all_18-60":
                    continue
                merged.append(row)

    merged.extend(zh_rows)

    merged.sort(key=lambda r: (
        r.get("group_id", ""),
        0 if r.get("metric_level") == "domain" else 1,
        r.get("metric_code", ""),
    ))

    seed_path.parent.mkdir(parents=True, exist_ok=True)
    with seed_path.open("w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(merged)

    print(f"[big5_build_zhcn_xu_bootstrap] merged rows={len(merged)} -> {seed_path}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
